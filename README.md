# Visual QA with Pytorch
        An implementation of paper "VQA: Visual Question Answering" with some changes.
    ResNet34 is taken instead of VGGNet and the pre-trained Word2Vec model is used 
    instead of training word embeddings from scratch.

### Paper
    "VQA: Visual Question Answering"
    URL: https://arxiv.org/abs/1505.00468 
    
### Dataset
    URL: https://visualqa.org/download.html
